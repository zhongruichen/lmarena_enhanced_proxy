# api_server.py
# æ–°ä¸€ä»£ LMArena Bridge åç«¯æœåŠ¡

import asyncio
import json
import logging
import os
import sys
import subprocess
import time
import uuid
import re
import threading
import random
import mimetypes
from datetime import datetime
from contextlib import asynccontextmanager

import uvicorn
import requests
from packaging.version import parse as parse_version
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse, Response


# --- åŸºç¡€é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- å…¨å±€çŠ¶æ€ä¸é…ç½® ---
CONFIG = {} # å­˜å‚¨ä» config.jsonc åŠ è½½çš„é…ç½®
# browser_ws ç”¨äºå­˜å‚¨ä¸å•ä¸ªæ²¹çŒ´è„šæœ¬çš„ WebSocket è¿æ¥ã€‚
# æ³¨æ„ï¼šæ­¤æ¶æ„å‡å®šåªæœ‰ä¸€ä¸ªæµè§ˆå™¨æ ‡ç­¾é¡µåœ¨å·¥ä½œã€‚
# å¦‚æœéœ€è¦æ”¯æŒå¤šä¸ªå¹¶å‘æ ‡ç­¾é¡µï¼Œéœ€è¦å°†æ­¤æ‰©å±•ä¸ºå­—å…¸ç®¡ç†å¤šä¸ªè¿æ¥ã€‚
browser_ws: WebSocket | None = None
# response_channels ç”¨äºå­˜å‚¨æ¯ä¸ª API è¯·æ±‚çš„å“åº”é˜Ÿåˆ—ã€‚
# é”®æ˜¯ request_idï¼Œå€¼æ˜¯ asyncio.Queueã€‚
response_channels: dict[str, asyncio.Queue] = {}
last_activity_time = None # è®°å½•æœ€åä¸€æ¬¡æ´»åŠ¨çš„æ—¶é—´
idle_monitor_thread = None # ç©ºé—²ç›‘æ§çº¿ç¨‹
main_event_loop = None # ä¸»äº‹ä»¶å¾ªç¯

# --- æ¨¡å‹æ˜ å°„ ---
# MODEL_NAME_TO_ID_MAP ç°åœ¨å°†å­˜å‚¨æ›´ä¸°å¯Œçš„å¯¹è±¡ï¼š { "model_name": {"id": "...", "type": "..."} }
MODEL_NAME_TO_ID_MAP = {}
MODEL_ENDPOINT_MAP = {} # æ–°å¢ï¼šç”¨äºå­˜å‚¨æ¨¡å‹åˆ° session/message ID çš„æ˜ å°„
DEFAULT_MODEL_ID = None # é»˜è®¤æ¨¡å‹id: None

def load_model_endpoint_map():
    """ä» model_endpoint_map.json åŠ è½½æ¨¡å‹åˆ°ç«¯ç‚¹çš„æ˜ å°„ã€‚"""
    global MODEL_ENDPOINT_MAP
    try:
        with open('model_endpoint_map.json', 'r', encoding='utf-8') as f:
            content = f.read()
            # å…è®¸ç©ºæ–‡ä»¶
            if not content.strip():
                MODEL_ENDPOINT_MAP = {}
            else:
                MODEL_ENDPOINT_MAP = json.loads(content)
        logger.info(f"æˆåŠŸä» 'model_endpoint_map.json' åŠ è½½äº† {len(MODEL_ENDPOINT_MAP)} ä¸ªæ¨¡å‹ç«¯ç‚¹æ˜ å°„ã€‚")
    except FileNotFoundError:
        logger.warning("'model_endpoint_map.json' æ–‡ä»¶æœªæ‰¾åˆ°ã€‚å°†ä½¿ç”¨ç©ºæ˜ å°„ã€‚")
        MODEL_ENDPOINT_MAP = {}
    except json.JSONDecodeError as e:
        logger.error(f"åŠ è½½æˆ–è§£æ 'model_endpoint_map.json' å¤±è´¥: {e}ã€‚å°†ä½¿ç”¨ç©ºæ˜ å°„ã€‚")
        MODEL_ENDPOINT_MAP = {}

def load_config():
    """ä» config.jsonc åŠ è½½é…ç½®ï¼Œå¹¶å¤„ç† JSONC æ³¨é‡Šã€‚"""
    global CONFIG
    try:
        with open('config.jsonc', 'r', encoding='utf-8') as f:
            content = f.read()
            # ç§»é™¤ // è¡Œæ³¨é‡Šå’Œ /* */ å—æ³¨é‡Š
            json_content = re.sub(r'//.*', '', content)
            json_content = re.sub(r'/\*.*?\*/', '', json_content, flags=re.DOTALL)
            CONFIG = json.loads(json_content)
        logger.info("æˆåŠŸä» 'config.jsonc' åŠ è½½é…ç½®ã€‚")
        # æ‰“å°å…³é”®é…ç½®çŠ¶æ€
        logger.info(f"  - é…’é¦†æ¨¡å¼ (Tavern Mode): {'âœ… å¯ç”¨' if CONFIG.get('tavern_mode_enabled') else 'âŒ ç¦ç”¨'}")
        logger.info(f"  - ç»•è¿‡æ¨¡å¼ (Bypass Mode): {'âœ… å¯ç”¨' if CONFIG.get('bypass_enabled') else 'âŒ ç¦ç”¨'}")
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logger.error(f"åŠ è½½æˆ–è§£æ 'config.jsonc' å¤±è´¥: {e}ã€‚å°†ä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
        CONFIG = {}

def load_model_map():
    """ä» models.json åŠ è½½æ¨¡å‹æ˜ å°„ï¼Œæ”¯æŒ 'id:type' æ ¼å¼ã€‚"""
    global MODEL_NAME_TO_ID_MAP
    try:
        with open('models.json', 'r', encoding='utf-8') as f:
            raw_map = json.load(f)
            
        processed_map = {}
        for name, value in raw_map.items():
            if isinstance(value, str) and ':' in value:
                parts = value.split(':', 1)
                model_id = parts[0] if parts[0].lower() != 'null' else None
                model_type = parts[1]
                processed_map[name] = {"id": model_id, "type": model_type}
            else:
                # é»˜è®¤æˆ–æ—§æ ¼å¼å¤„ç†
                processed_map[name] = {"id": value, "type": "text"}

        MODEL_NAME_TO_ID_MAP = processed_map
        logger.info(f"æˆåŠŸä» 'models.json' åŠ è½½å¹¶è§£æäº† {len(MODEL_NAME_TO_ID_MAP)} ä¸ªæ¨¡å‹ã€‚")

    except (FileNotFoundError, json.JSONDecodeError) as e:
        logger.error(f"åŠ è½½ 'models.json' å¤±è´¥: {e}ã€‚å°†ä½¿ç”¨ç©ºæ¨¡å‹åˆ—è¡¨ã€‚")
        MODEL_NAME_TO_ID_MAP = {}

# --- æ›´æ–°æ£€æŸ¥ ---
GITHUB_REPO = "Lianues/LMArenaBridge"

def download_and_extract_update(version):
    """ä¸‹è½½å¹¶è§£å‹æœ€æ–°ç‰ˆæœ¬åˆ°ä¸´æ—¶æ–‡ä»¶å¤¹ã€‚"""
    update_dir = "update_temp"
    if not os.path.exists(update_dir):
        os.makedirs(update_dir)

    try:
        zip_url = f"https://github.com/{GITHUB_REPO}/archive/refs/heads/main.zip"
        logger.info(f"æ­£åœ¨ä» {zip_url} ä¸‹è½½æ–°ç‰ˆæœ¬...")
        response = requests.get(zip_url, timeout=60)
        response.raise_for_status()

        # éœ€è¦å¯¼å…¥ zipfile å’Œ io
        import zipfile
        import io
        with zipfile.ZipFile(io.BytesIO(response.content)) as z:
            z.extractall(update_dir)
        
        logger.info(f"æ–°ç‰ˆæœ¬å·²æˆåŠŸä¸‹è½½å¹¶è§£å‹åˆ° '{update_dir}' æ–‡ä»¶å¤¹ã€‚")
        return True
    except requests.RequestException as e:
        logger.error(f"ä¸‹è½½æ›´æ–°å¤±è´¥: {e}")
    except zipfile.BadZipFile:
        logger.error("ä¸‹è½½çš„æ–‡ä»¶ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„zipå‹ç¼©åŒ…ã€‚")
    except Exception as e:
        logger.error(f"è§£å‹æ›´æ–°æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    
    return False

def check_for_updates():
    """ä» GitHub æ£€æŸ¥æ–°ç‰ˆæœ¬ã€‚"""
    if not CONFIG.get("enable_auto_update", True):
        logger.info("è‡ªåŠ¨æ›´æ–°å·²ç¦ç”¨ï¼Œè·³è¿‡æ£€æŸ¥ã€‚")
        return

    current_version = CONFIG.get("version", "0.0.0")
    logger.info(f"å½“å‰ç‰ˆæœ¬: {current_version}ã€‚æ­£åœ¨ä» GitHub æ£€æŸ¥æ›´æ–°...")

    try:
        config_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main/config.jsonc"
        response = requests.get(config_url, timeout=10)
        response.raise_for_status()

        jsonc_content = response.text
        json_content = re.sub(r'//.*', '', jsonc_content)
        json_content = re.sub(r'/\*.*?\*/', '', json_content, flags=re.DOTALL)
        remote_config = json.loads(json_content)
        
        remote_version_str = remote_config.get("version")
        if not remote_version_str:
            logger.warning("è¿œç¨‹é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ç‰ˆæœ¬å·ï¼Œè·³è¿‡æ›´æ–°æ£€æŸ¥ã€‚")
            return

        if parse_version(remote_version_str) > parse_version(current_version):
            logger.info("="*60)
            logger.info(f"ğŸ‰ å‘ç°æ–°ç‰ˆæœ¬! ğŸ‰")
            logger.info(f"  - å½“å‰ç‰ˆæœ¬: {current_version}")
            logger.info(f"  - æœ€æ–°ç‰ˆæœ¬: {remote_version_str}")
            if download_and_extract_update(remote_version_str):
                logger.info("å‡†å¤‡åº”ç”¨æ›´æ–°ã€‚æœåŠ¡å™¨å°†åœ¨5ç§’åå…³é—­å¹¶å¯åŠ¨æ›´æ–°è„šæœ¬ã€‚")
                time.sleep(5)
                update_script_path = os.path.join("modules", "update_script.py")
                # ä½¿ç”¨ Popen å¯åŠ¨ç‹¬ç«‹è¿›ç¨‹
                subprocess.Popen([sys.executable, update_script_path])
                # ä¼˜é›…åœ°é€€å‡ºå½“å‰æœåŠ¡å™¨è¿›ç¨‹
                os._exit(0)
            else:
                logger.error(f"è‡ªåŠ¨æ›´æ–°å¤±è´¥ã€‚è¯·è®¿é—® https://github.com/{GITHUB_REPO}/releases/latest æ‰‹åŠ¨ä¸‹è½½ã€‚")
            logger.info("="*60)
        else:
            logger.info("æ‚¨çš„ç¨‹åºå·²æ˜¯æœ€æ–°ç‰ˆæœ¬ã€‚")

    except requests.RequestException as e:
        logger.error(f"æ£€æŸ¥æ›´æ–°å¤±è´¥: {e}")
    except json.JSONDecodeError:
        logger.error("è§£æè¿œç¨‹é…ç½®æ–‡ä»¶å¤±è´¥ã€‚")
    except Exception as e:
        logger.error(f"æ£€æŸ¥æ›´æ–°æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

# --- æ¨¡å‹æ›´æ–° ---
def extract_models_from_html(html_content):
    """
    ä» HTML å†…å®¹ä¸­æå–å®Œæ•´çš„æ¨¡å‹JSONå¯¹è±¡ï¼Œä½¿ç”¨æ‹¬å·åŒ¹é…ç¡®ä¿å®Œæ•´æ€§ã€‚
    """
    models = []
    model_names = set()
    
    # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ¨¡å‹JSONå¯¹è±¡çš„èµ·å§‹ä½ç½®
    for start_match in re.finditer(r'\{\\"id\\":\\"[a-f0-9-]+\\"', html_content):
        start_index = start_match.start()
        
        # ä»èµ·å§‹ä½ç½®å¼€å§‹ï¼Œè¿›è¡ŒèŠ±æ‹¬å·åŒ¹é…
        open_braces = 0
        end_index = -1
        
        # ä¼˜åŒ–ï¼šè®¾ç½®ä¸€ä¸ªåˆç†çš„æœç´¢ä¸Šé™ï¼Œé¿å…æ— é™å¾ªç¯
        search_limit = start_index + 10000 # å‡è®¾ä¸€ä¸ªæ¨¡å‹å®šä¹‰ä¸ä¼šè¶…è¿‡10000ä¸ªå­—ç¬¦
        
        for i in range(start_index, min(len(html_content), search_limit)):
            if html_content[i] == '{':
                open_braces += 1
            elif html_content[i] == '}':
                open_braces -= 1
                if open_braces == 0:
                    end_index = i + 1
                    break
        
        if end_index != -1:
            # æå–å®Œæ•´çš„ã€è½¬ä¹‰çš„JSONå­—ç¬¦ä¸²
            json_string_escaped = html_content[start_index:end_index]
            
            # åè½¬ä¹‰
            json_string = json_string_escaped.replace('\\"', '"').replace('\\\\', '\\')
            
            try:
                model_data = json.loads(json_string)
                model_name = model_data.get('publicName')
                
                # ä½¿ç”¨publicNameå»é‡
                if model_name and model_name not in model_names:
                    models.append(model_data)
                    model_names.add(model_name)
            except json.JSONDecodeError as e:
                logger.warning(f"è§£ææå–çš„JSONå¯¹è±¡æ—¶å‡ºé”™: {e} - å†…å®¹: {json_string[:150]}...")
                continue

    if models:
        logger.info(f"æˆåŠŸæå–å¹¶è§£æäº† {len(models)} ä¸ªç‹¬ç«‹æ¨¡å‹ã€‚")
        return models
    else:
        logger.error("é”™è¯¯ï¼šåœ¨HTMLå“åº”ä¸­æ‰¾ä¸åˆ°ä»»ä½•åŒ¹é…çš„å®Œæ•´æ¨¡å‹JSONå¯¹è±¡ã€‚")
        return None

def save_available_models(new_models_list, models_path="available_models.json"):
    """
    å°†æå–åˆ°çš„å®Œæ•´æ¨¡å‹å¯¹è±¡åˆ—è¡¨ä¿å­˜åˆ°æŒ‡å®šçš„JSONæ–‡ä»¶ä¸­ã€‚
    """
    logger.info(f"æ£€æµ‹åˆ° {len(new_models_list)} ä¸ªæ¨¡å‹ï¼Œæ­£åœ¨æ›´æ–° '{models_path}'...")
    
    try:
        with open(models_path, 'w', encoding='utf-8') as f:
            # ç›´æ¥å°†å®Œæ•´çš„æ¨¡å‹å¯¹è±¡åˆ—è¡¨å†™å…¥æ–‡ä»¶
            json.dump(new_models_list, f, indent=4, ensure_ascii=False)
        logger.info(f"âœ… '{models_path}' å·²æˆåŠŸæ›´æ–°ï¼ŒåŒ…å« {len(new_models_list)} ä¸ªæ¨¡å‹ã€‚")
    except IOError as e:
        logger.error(f"âŒ å†™å…¥ '{models_path}' æ–‡ä»¶æ—¶å‡ºé”™: {e}")

# --- è‡ªåŠ¨é‡å¯é€»è¾‘ ---
def restart_server():
    """ä¼˜é›…åœ°é€šçŸ¥å®¢æˆ·ç«¯åˆ·æ–°ï¼Œç„¶åé‡å¯æœåŠ¡å™¨ã€‚"""
    logger.warning("="*60)
    logger.warning("æ£€æµ‹åˆ°æœåŠ¡å™¨ç©ºé—²è¶…æ—¶ï¼Œå‡†å¤‡è‡ªåŠ¨é‡å¯...")
    logger.warning("="*60)
    
    # 1. (å¼‚æ­¥) é€šçŸ¥æµè§ˆå™¨åˆ·æ–°
    async def notify_browser_refresh():
        if browser_ws:
            try:
                # ä¼˜å…ˆå‘é€ 'reconnect' æŒ‡ä»¤ï¼Œè®©å‰ç«¯çŸ¥é“è¿™æ˜¯ä¸€ä¸ªè®¡åˆ’å†…çš„é‡å¯
                await browser_ws.send_text(json.dumps({"command": "reconnect"}, ensure_ascii=False))
                logger.info("å·²å‘æµè§ˆå™¨å‘é€ 'reconnect' æŒ‡ä»¤ã€‚")
            except Exception as e:
                logger.error(f"å‘é€ 'reconnect' æŒ‡ä»¤å¤±è´¥: {e}")
    
    # åœ¨ä¸»äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥é€šçŸ¥å‡½æ•°
    # ä½¿ç”¨`asyncio.run_coroutine_threadsafe`ç¡®ä¿çº¿ç¨‹å®‰å…¨
    if browser_ws and browser_ws.client_state.name == 'CONNECTED' and main_event_loop:
        asyncio.run_coroutine_threadsafe(notify_browser_refresh(), main_event_loop)
    
    # 2. å»¶è¿Ÿå‡ ç§’ä»¥ç¡®ä¿æ¶ˆæ¯å‘é€
    time.sleep(3)
    
    # 3. æ‰§è¡Œé‡å¯
    logger.info("æ­£åœ¨é‡å¯æœåŠ¡å™¨...")
    os.execv(sys.executable, ['python'] + sys.argv)

def idle_monitor():
    """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼Œç›‘æ§æœåŠ¡å™¨æ˜¯å¦ç©ºé—²ã€‚"""
    global last_activity_time
    
    # ç­‰å¾…ï¼Œç›´åˆ° last_activity_time è¢«é¦–æ¬¡è®¾ç½®
    while last_activity_time is None:
        time.sleep(1)
        
    logger.info("ç©ºé—²ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨ã€‚")
    
    while True:
        if CONFIG.get("enable_idle_restart", False):
            timeout = CONFIG.get("idle_restart_timeout_seconds", 300)
            
            # å¦‚æœè¶…æ—¶è®¾ç½®ä¸º-1ï¼Œåˆ™ç¦ç”¨é‡å¯æ£€æŸ¥
            if timeout == -1:
                time.sleep(10) # ä»ç„¶éœ€è¦ä¼‘çœ ä»¥é¿å…ç¹å¿™å¾ªç¯
                continue

            idle_time = (datetime.now() - last_activity_time).total_seconds()
            
            if idle_time > timeout:
                logger.info(f"æœåŠ¡å™¨ç©ºé—²æ—¶é—´ ({idle_time:.0f}s) å·²è¶…è¿‡é˜ˆå€¼ ({timeout}s)ã€‚")
                restart_server()
                break # é€€å‡ºå¾ªç¯ï¼Œå› ä¸ºè¿›ç¨‹å³å°†è¢«æ›¿æ¢
                
        # æ¯ 10 ç§’æ£€æŸ¥ä¸€æ¬¡
        time.sleep(10)

# --- FastAPI ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åœ¨æœåŠ¡å™¨å¯åŠ¨æ—¶è¿è¡Œçš„ç”Ÿå‘½å‘¨æœŸå‡½æ•°ã€‚"""
    global idle_monitor_thread, last_activity_time, main_event_loop
    main_event_loop = asyncio.get_running_loop() # è·å–ä¸»äº‹ä»¶å¾ªç¯
    load_config() # é¦–å…ˆåŠ è½½é…ç½®
    
    # --- æ‰“å°å½“å‰çš„æ“ä½œæ¨¡å¼ ---
    mode = CONFIG.get("id_updater_last_mode", "direct_chat")
    target = CONFIG.get("id_updater_battle_target", "A")
    logger.info("="*60)
    logger.info(f"  å½“å‰æ“ä½œæ¨¡å¼: {mode.upper()}")
    if mode == 'battle':
        logger.info(f"  - Battle æ¨¡å¼ç›®æ ‡: Assistant {target}")
    logger.info("  (å¯é€šè¿‡è¿è¡Œ id_updater.py ä¿®æ”¹æ¨¡å¼)")
    logger.info("="*60)

    check_for_updates() # æ£€æŸ¥ç¨‹åºæ›´æ–°
    load_model_map() # é‡æ–°å¯ç”¨æ¨¡å‹åŠ è½½
    load_model_endpoint_map() # åŠ è½½æ¨¡å‹ç«¯ç‚¹æ˜ å°„
    logger.info("æœåŠ¡å™¨å¯åŠ¨å®Œæˆã€‚ç­‰å¾…æ²¹çŒ´è„šæœ¬è¿æ¥...")

    # åœ¨æ¨¡å‹æ›´æ–°åï¼Œæ ‡è®°æ´»åŠ¨æ—¶é—´çš„èµ·ç‚¹
    last_activity_time = datetime.now()
    
    # å¯åŠ¨ç©ºé—²ç›‘æ§çº¿ç¨‹
    if CONFIG.get("enable_idle_restart", False):
        idle_monitor_thread = threading.Thread(target=idle_monitor, daemon=True)
        idle_monitor_thread.start()
        

    yield
    logger.info("æœåŠ¡å™¨æ­£åœ¨å…³é—­ã€‚")

app = FastAPI(lifespan=lifespan)

# --- CORS ä¸­é—´ä»¶é…ç½® ---
# å…è®¸æ‰€æœ‰æ¥æºã€æ‰€æœ‰æ–¹æ³•ã€æ‰€æœ‰è¯·æ±‚å¤´ï¼Œè¿™å¯¹äºæœ¬åœ°å¼€å‘å·¥å…·æ˜¯å®‰å…¨çš„ã€‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- è¾…åŠ©å‡½æ•° ---
def save_config():
    """å°†å½“å‰çš„ CONFIG å¯¹è±¡å†™å› config.jsonc æ–‡ä»¶ï¼Œä¿ç•™æ³¨é‡Šã€‚"""
    try:
        # è¯»å–åŸå§‹æ–‡ä»¶ä»¥ä¿ç•™æ³¨é‡Šç­‰
        with open('config.jsonc', 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å®‰å…¨åœ°æ›¿æ¢å€¼
        def replacer(key, value, content):
            # è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼ä¼šæ‰¾åˆ° keyï¼Œç„¶ååŒ¹é…å®ƒçš„ value éƒ¨åˆ†ï¼Œç›´åˆ°é€—å·æˆ–å³èŠ±æ‹¬å·
            pattern = re.compile(rf'("{key}"\s*:\s*").*?("?)(,?\s*)$', re.MULTILINE)
            replacement = rf'\g<1>{value}\g<2>\g<3>'
            if not pattern.search(content): # å¦‚æœ key ä¸å­˜åœ¨ï¼Œå°±æ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                 content = re.sub(r'}\s*$', f'  ,"{key}": "{value}"\n}}', content)
            else:
                 content = pattern.sub(replacement, content)
            return content

        content_str = "".join(lines)
        content_str = replacer("session_id", CONFIG["session_id"], content_str)
        content_str = replacer("message_id", CONFIG["message_id"], content_str)
        
        with open('config.jsonc', 'w', encoding='utf-8') as f:
            f.write(content_str)
        logger.info("âœ… æˆåŠŸå°†ä¼šè¯ä¿¡æ¯æ›´æ–°åˆ° config.jsoncã€‚")
    except Exception as e:
        logger.error(f"âŒ å†™å…¥ config.jsonc æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


def _process_openai_message(message: dict) -> dict:
    """
    å¤„ç†OpenAIæ¶ˆæ¯ï¼Œåˆ†ç¦»æ–‡æœ¬å’Œé™„ä»¶ã€‚
    - å°†å¤šæ¨¡æ€å†…å®¹åˆ—è¡¨åˆ†è§£ä¸ºçº¯æ–‡æœ¬å’Œé™„ä»¶åˆ—è¡¨ã€‚
    - ç¡®ä¿ user è§’è‰²çš„ç©ºå†…å®¹è¢«æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œä»¥é¿å… LMArena å‡ºé”™ã€‚
    - ä¸ºé™„ä»¶ç”ŸæˆåŸºç¡€ç»“æ„ã€‚
    """
    content = message.get("content")
    role = message.get("role")
    attachments = []
    text_content = ""

    if isinstance(content, list):
        
        text_parts = []
        for part in content:
            if part.get("type") == "text":
                text_parts.append(part.get("text", ""))
            elif part.get("type") == "image_url":
                image_url_data = part.get("image_url", {})
                url = image_url_data.get("url")

                # æ–°å¢é€»è¾‘ï¼šå…è®¸å®¢æˆ·ç«¯é€šè¿‡ detail å­—æ®µä¼ é€’åŸå§‹æ–‡ä»¶å
                # detail å­—æ®µæ˜¯ OpenAI Vision API çš„ä¸€éƒ¨åˆ†ï¼Œè¿™é‡Œæˆ‘ä»¬å¤ç”¨å®ƒ
                original_filename = image_url_data.get("detail")

                if url and url.startswith("data:"):
                    try:
                        content_type = url.split(';')[0].split(':')[1]
                        
                        # å¦‚æœå®¢æˆ·ç«¯æä¾›äº†åŸå§‹æ–‡ä»¶åï¼Œç›´æ¥ä½¿ç”¨å®ƒ
                        if original_filename and isinstance(original_filename, str):
                            file_name = original_filename
                            logger.info(f"æˆåŠŸå¤„ç†ä¸€ä¸ªé™„ä»¶ (ä½¿ç”¨åŸå§‹æ–‡ä»¶å): {file_name}")
                        else:
                            # å¦åˆ™ï¼Œå›é€€åˆ°æ—§çš„ã€åŸºäºUUIDçš„å‘½åé€»è¾‘
                            main_type, sub_type = content_type.split('/') if '/' in content_type else ('application', 'octet-stream')
                            
                            if main_type == "image": prefix = "image"
                            elif main_type == "audio": prefix = "audio"
                            else: prefix = "file"
                            
                            guessed_extension = mimetypes.guess_extension(content_type)
                            if guessed_extension:
                                file_extension = guessed_extension.lstrip('.')
                            else:
                                file_extension = sub_type if len(sub_type) < 20 else 'bin'
                            
                            file_name = f"{prefix}_{uuid.uuid4()}.{file_extension}"
                            logger.info(f"æˆåŠŸå¤„ç†ä¸€ä¸ªé™„ä»¶ (ç”Ÿæˆæ–‡ä»¶å): {file_name}")

                        attachments.append({
                            "name": file_name,
                            "contentType": content_type,
                            "url": url
                        })
                    except (IndexError, ValueError) as e:
                        logger.warning(f"æ— æ³•è§£æçš„ base64 data URI: {url[:60]}... é”™è¯¯: {e}")

        text_content = "\n\n".join(text_parts)
    elif isinstance(content, str):
        text_content = content

    
    if role == "user" and not text_content.strip():
        text_content = " "

    return {
        "role": role,
        "content": text_content,
        "attachments": attachments
    }

def convert_openai_to_lmarena_payload(openai_data: dict, session_id: str, message_id: str, mode_override: str = None, battle_target_override: str = None) -> dict:
    """
    å°† OpenAI è¯·æ±‚ä½“è½¬æ¢ä¸ºæ²¹çŒ´è„šæœ¬æ‰€éœ€çš„ç®€åŒ–è½½è·ï¼Œå¹¶åº”ç”¨é…’é¦†æ¨¡å¼ã€ç»•è¿‡æ¨¡å¼ä»¥åŠå¯¹æˆ˜æ¨¡å¼ã€‚
    æ–°å¢äº†æ¨¡å¼è¦†ç›–å‚æ•°ï¼Œä»¥æ”¯æŒæ¨¡å‹ç‰¹å®šçš„ä¼šè¯æ¨¡å¼ã€‚
    """
    # 1. è§„èŒƒåŒ–è§’è‰²å¹¶å¤„ç†æ¶ˆæ¯
    #    - å°†éæ ‡å‡†çš„ 'developer' è§’è‰²è½¬æ¢ä¸º 'system' ä»¥æé«˜å…¼å®¹æ€§ã€‚
    #    - åˆ†ç¦»æ–‡æœ¬å’Œé™„ä»¶ã€‚
    messages = openai_data.get("messages", [])
    for msg in messages:
        if msg.get("role") == "developer":
            msg["role"] = "system"
            logger.info("æ¶ˆæ¯è§’è‰²è§„èŒƒåŒ–ï¼šå°† 'developer' è½¬æ¢ä¸º 'system'ã€‚")
            
    processed_messages = [_process_openai_message(msg.copy()) for msg in messages]

    # 2. åº”ç”¨é…’é¦†æ¨¡å¼ (Tavern Mode)
    if CONFIG.get("tavern_mode_enabled"):
        system_prompts = [msg['content'] for msg in processed_messages if msg['role'] == 'system']
        other_messages = [msg for msg in processed_messages if msg['role'] != 'system']
        
        merged_system_prompt = "\n\n".join(system_prompts)
        final_messages = []
        
        if merged_system_prompt:
            # ç³»ç»Ÿæ¶ˆæ¯ä¸åº”æœ‰é™„ä»¶
            final_messages.append({"role": "system", "content": merged_system_prompt, "attachments": []})
        
        final_messages.extend(other_messages)
        processed_messages = final_messages

    # 3. ç¡®å®šç›®æ ‡æ¨¡å‹ ID
    model_name = openai_data.get("model", "claude-3-5-sonnet-20241022")
    model_info = MODEL_NAME_TO_ID_MAP.get(model_name, {}) # å…³é”®ä¿®å¤ï¼šç¡®ä¿ model_info æ€»æ˜¯ä¸€ä¸ªå­—å…¸
    
    target_model_id = None
    if model_info:
        target_model_id = model_info.get("id")
    else:
        logger.warning(f"æ¨¡å‹ '{model_name}' åœ¨ 'models.json' ä¸­æœªæ‰¾åˆ°ã€‚è¯·æ±‚å°†ä¸å¸¦ç‰¹å®šæ¨¡å‹IDå‘é€ã€‚")

    if not target_model_id:
        logger.warning(f"æ¨¡å‹ '{model_name}' åœ¨ 'models.json' ä¸­æœªæ‰¾åˆ°å¯¹åº”çš„IDã€‚è¯·æ±‚å°†ä¸å¸¦ç‰¹å®šæ¨¡å‹IDå‘é€ã€‚")

    # 4. æ„å»ºæ¶ˆæ¯æ¨¡æ¿
    message_templates = []
    for msg in processed_messages:
        message_templates.append({
            "role": msg["role"],
            "content": msg.get("content", ""),
            "attachments": msg.get("attachments", [])
        })

    # 5. åº”ç”¨ç»•è¿‡æ¨¡å¼ (Bypass Mode) - ä»…å¯¹æ–‡æœ¬æ¨¡å‹ç”Ÿæ•ˆ
    model_type = model_info.get("type", "text")
    if CONFIG.get("bypass_enabled") and model_type == "text":
        # ç»•è¿‡æ¨¡å¼æ€»æ˜¯æ·»åŠ ä¸€ä¸ª position 'a' çš„ç”¨æˆ·æ¶ˆæ¯
        logger.info("ç»•è¿‡æ¨¡å¼å·²å¯ç”¨ï¼Œæ­£åœ¨æ³¨å…¥ä¸€ä¸ªç©ºçš„ç”¨æˆ·æ¶ˆæ¯ã€‚")
        message_templates.append({"role": "user", "content": " ", "participantPosition": "a", "attachments": []})

    # 6. åº”ç”¨å‚ä¸è€…ä½ç½® (Participant Position)
    # ä¼˜å…ˆä½¿ç”¨è¦†ç›–çš„æ¨¡å¼ï¼Œå¦åˆ™å›é€€åˆ°å…¨å±€é…ç½®
    mode = mode_override or CONFIG.get("id_updater_last_mode", "direct_chat")
    target_participant = battle_target_override or CONFIG.get("id_updater_battle_target", "A")
    target_participant = target_participant.lower() # ç¡®ä¿æ˜¯å°å†™

    logger.info(f"æ­£åœ¨æ ¹æ®æ¨¡å¼ '{mode}' (ç›®æ ‡: {target_participant if mode == 'battle' else 'N/A'}) è®¾ç½® Participant Positions...")

    for msg in message_templates:
        if msg['role'] == 'system':
            if mode == 'battle':
                # Battle æ¨¡å¼: system ä¸ç”¨æˆ·é€‰æ‹©çš„åŠ©æ‰‹åœ¨åŒä¸€è¾¹ (Aåˆ™a, Båˆ™b)
                msg['participantPosition'] = target_participant
            else:
                # DirectChat æ¨¡å¼: system å›ºå®šä¸º 'b'
                msg['participantPosition'] = 'b'
        elif mode == 'battle':
            # Battle æ¨¡å¼ä¸‹ï¼Œé system æ¶ˆæ¯ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç›®æ ‡ participant
            msg['participantPosition'] = target_participant
        else: # DirectChat æ¨¡å¼
            # DirectChat æ¨¡å¼ä¸‹ï¼Œé system æ¶ˆæ¯ä½¿ç”¨é»˜è®¤çš„ 'a'
            msg['participantPosition'] = 'a'

    return {
        "message_templates": message_templates,
        "target_model_id": target_model_id,
        "session_id": session_id,
        "message_id": message_id
    }

# --- OpenAI æ ¼å¼åŒ–è¾…åŠ©å‡½æ•° (ç¡®ä¿JSONåºåˆ—åŒ–ç¨³å¥) ---
def format_openai_chunk(content: str, model: str, request_id: str) -> str:
    """æ ¼å¼åŒ–ä¸º OpenAI æµå¼å—ã€‚"""
    chunk = {
        "id": request_id, "object": "chat.completion.chunk",
        "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {"content": content}, "finish_reason": None}]
    }
    return f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

def format_openai_finish_chunk(model: str, request_id: str, reason: str = 'stop') -> str:
    """æ ¼å¼åŒ–ä¸º OpenAI ç»“æŸå—ã€‚"""
    chunk = {
        "id": request_id, "object": "chat.completion.chunk",
        "created": int(time.time()), "model": model,
        "choices": [{"index": 0, "delta": {}, "finish_reason": reason}]
    }
    return f"data: {json.dumps(chunk, ensure_ascii=False)}\n\ndata: [DONE]\n\n"

def format_openai_error_chunk(error_message: str, model: str, request_id: str) -> str:
    """æ ¼å¼åŒ–ä¸º OpenAI é”™è¯¯å—ã€‚"""
    content = f"\n\n[LMArena Bridge Error]: {error_message}"
    return format_openai_chunk(content, model, request_id)

def format_openai_non_stream_response(content: str, model: str, request_id: str, reason: str = 'stop') -> dict:
    """æ„å»ºç¬¦åˆ OpenAI è§„èŒƒçš„éæµå¼å“åº”ä½“ã€‚"""
    return {
        "id": request_id,
        "object": "chat.completion",
        "created": int(time.time()),
        "model": model,
        "choices": [{
            "index": 0,
            "message": {"role": "assistant", "content": content},
            "finish_reason": reason,
        }],
        "usage": {
            "prompt_tokens": 0,
            "completion_tokens": len(content) // 4,
            "total_tokens": len(content) // 4,
        },
    }

async def _process_lmarena_stream(request_id: str):
    """
    æ ¸å¿ƒå†…éƒ¨ç”Ÿæˆå™¨ï¼šå¤„ç†æ¥è‡ªæµè§ˆå™¨çš„åŸå§‹æ•°æ®æµï¼Œå¹¶äº§ç”Ÿç»“æ„åŒ–äº‹ä»¶ã€‚
    äº‹ä»¶ç±»å‹: ('content', str), ('finish', str), ('error', str)
    """
    queue = response_channels.get(request_id)
    if not queue:
        logger.error(f"PROCESSOR [ID: {request_id[:8]}]: æ— æ³•æ‰¾åˆ°å“åº”é€šé“ã€‚")
        yield 'error', 'Internal server error: response channel not found.'
        return

    buffer = ""
    timeout = CONFIG.get("stream_response_timeout_seconds",360)
    text_pattern = re.compile(r'[ab]0:"((?:\\.|[^"\\])*)"')
    # æ–°å¢ï¼šç”¨äºåŒ¹é…å’Œæå–å›¾ç‰‡URLçš„æ­£åˆ™è¡¨è¾¾å¼
    image_pattern = re.compile(r'[ab]2:(\[.*?\])')
    finish_pattern = re.compile(r'[ab]d:(\{.*?"finishReason".*?\})')
    error_pattern = re.compile(r'(\{\s*"error".*?\})', re.DOTALL)
    cloudflare_patterns = [r'<title>Just a moment...</title>', r'Enable JavaScript and cookies to continue']

    try:
        while True:
            try:
                raw_data = await asyncio.wait_for(queue.get(), timeout=timeout)
            except asyncio.TimeoutError:
                logger.warning(f"PROCESSOR [ID: {request_id[:8]}]: ç­‰å¾…æµè§ˆå™¨æ•°æ®è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ã€‚")
                yield 'error', f'Response timed out after {timeout} seconds.'
                return

            # 1. æ£€æŸ¥æ¥è‡ª WebSocket ç«¯çš„ç›´æ¥é”™è¯¯æˆ–ç»ˆæ­¢ä¿¡å·
            if isinstance(raw_data, dict) and 'error' in raw_data:
                error_msg = raw_data.get('error', 'Unknown browser error')
                
                # å¢å¼ºé”™è¯¯å¤„ç†
                if isinstance(error_msg, str):
                    # 1. æ£€æŸ¥ 413 é™„ä»¶è¿‡å¤§é”™è¯¯
                    if '413' in error_msg or 'too large' in error_msg.lower():
                        friendly_error_msg = "ä¸Šä¼ å¤±è´¥ï¼šé™„ä»¶å¤§å°è¶…è¿‡äº† LMArena æœåŠ¡å™¨çš„é™åˆ¶ (é€šå¸¸æ˜¯ 5MBå·¦å³)ã€‚è¯·å°è¯•å‹ç¼©æ–‡ä»¶æˆ–ä¸Šä¼ æ›´å°çš„æ–‡ä»¶ã€‚"
                        logger.warning(f"PROCESSOR [ID: {request_id[:8]}]: æ£€æµ‹åˆ°é™„ä»¶è¿‡å¤§é”™è¯¯ (413)ã€‚")
                        yield 'error', friendly_error_msg
                        return

                    # 2. æ£€æŸ¥ Cloudflare éªŒè¯é¡µé¢
                    if any(re.search(p, error_msg, re.IGNORECASE) for p in cloudflare_patterns):
                        friendly_error_msg = "æ£€æµ‹åˆ° Cloudflare äººæœºéªŒè¯é¡µé¢ã€‚è¯·åœ¨æµè§ˆå™¨ä¸­åˆ·æ–° LMArena é¡µé¢å¹¶æ‰‹åŠ¨å®ŒæˆéªŒè¯ï¼Œç„¶åé‡è¯•è¯·æ±‚ã€‚"
                        if browser_ws:
                            try:
                                await browser_ws.send_text(json.dumps({"command": "refresh"}, ensure_ascii=False))
                                logger.info(f"PROCESSOR [ID: {request_id[:8]}]: åœ¨é”™è¯¯æ¶ˆæ¯ä¸­æ£€æµ‹åˆ°CFå¹¶å·²å‘é€åˆ·æ–°æŒ‡ä»¤ã€‚")
                            except Exception as e:
                                logger.error(f"PROCESSOR [ID: {request_id[:8]}]: å‘é€åˆ·æ–°æŒ‡ä»¤å¤±è´¥: {e}")
                        yield 'error', friendly_error_msg
                        return

                # 3. å…¶ä»–æœªçŸ¥é”™è¯¯
                yield 'error', error_msg
                return
            if raw_data == "[DONE]":
                break

            buffer += "".join(str(item) for item in raw_data) if isinstance(raw_data, list) else raw_data

            if any(re.search(p, buffer, re.IGNORECASE) for p in cloudflare_patterns):
                error_msg = "æ£€æµ‹åˆ° Cloudflare äººæœºéªŒè¯é¡µé¢ã€‚è¯·åœ¨æµè§ˆå™¨ä¸­åˆ·æ–° LMArena é¡µé¢å¹¶æ‰‹åŠ¨å®ŒæˆéªŒè¯ï¼Œç„¶åé‡è¯•è¯·æ±‚ã€‚"
                if browser_ws:
                    try:
                        await browser_ws.send_text(json.dumps({"command": "refresh"}, ensure_ascii=False))
                        logger.info(f"PROCESSOR [ID: {request_id[:8]}]: å·²å‘æµè§ˆå™¨å‘é€é¡µé¢åˆ·æ–°æŒ‡ä»¤ã€‚")
                    except Exception as e:
                        logger.error(f"PROCESSOR [ID: {request_id[:8]}]: å‘é€åˆ·æ–°æŒ‡ä»¤å¤±è´¥: {e}")
                yield 'error', error_msg
                return
            
            if (error_match := error_pattern.search(buffer)):
                try:
                    error_json = json.loads(error_match.group(1))
                    yield 'error', error_json.get("error", "æ¥è‡ª LMArena çš„æœªçŸ¥é”™è¯¯")
                    return
                except json.JSONDecodeError: pass

            # ä¼˜å…ˆå¤„ç†æ–‡æœ¬å†…å®¹
            while (match := text_pattern.search(buffer)):
                try:
                    text_content = json.loads(f'"{match.group(1)}"')
                    if text_content: yield 'content', text_content
                except (ValueError, json.JSONDecodeError): pass
                buffer = buffer[match.end():]

            # æ–°å¢ï¼šå¤„ç†å›¾ç‰‡å†…å®¹
            while (match := image_pattern.search(buffer)):
                try:
                    image_data_list = json.loads(match.group(1))
                    if isinstance(image_data_list, list) and image_data_list:
                        image_info = image_data_list[0]
                        if image_info.get("type") == "image" and "image" in image_info:
                            # å°†URLåŒ…è£…æˆMarkdownæ ¼å¼å¹¶ä½œä¸ºå†…å®¹å—yield
                            markdown_image = f"![Image]({image_info['image']})"
                            yield 'content', markdown_image
                except (json.JSONDecodeError, IndexError) as e:
                    logger.warning(f"è§£æå›¾ç‰‡URLæ—¶å‡ºé”™: {e}, buffer: {buffer[:150]}")
                buffer = buffer[match.end():]

            if (finish_match := finish_pattern.search(buffer)):
                try:
                    finish_data = json.loads(finish_match.group(1))
                    yield 'finish', finish_data.get("finishReason", "stop")
                except (json.JSONDecodeError, IndexError): pass
                buffer = buffer[finish_match.end():]

    except asyncio.CancelledError:
        logger.info(f"PROCESSOR [ID: {request_id[:8]}]: ä»»åŠ¡è¢«å–æ¶ˆã€‚")
    finally:
        if request_id in response_channels:
            del response_channels[request_id]
            logger.info(f"PROCESSOR [ID: {request_id[:8]}]: å“åº”é€šé“å·²æ¸…ç†ã€‚")

async def stream_generator(request_id: str, model: str):
    """å°†å†…éƒ¨äº‹ä»¶æµæ ¼å¼åŒ–ä¸º OpenAI SSE å“åº”ã€‚"""
    response_id = f"chatcmpl-{uuid.uuid4()}"
    logger.info(f"STREAMER [ID: {request_id[:8]}]: æµå¼ç”Ÿæˆå™¨å¯åŠ¨ã€‚")
    
    finish_reason_to_send = 'stop'  # é»˜è®¤çš„ç»“æŸåŸå› 

    async for event_type, data in _process_lmarena_stream(request_id):
        if event_type == 'content':
            yield format_openai_chunk(data, model, response_id)
        elif event_type == 'finish':
            # è®°å½•ç»“æŸåŸå› ï¼Œä½†ä¸è¦ç«‹å³è¿”å›ï¼Œç­‰å¾…æµè§ˆå™¨å‘é€ [DONE]
            finish_reason_to_send = data
            if data == 'content-filter':
                warning_msg = "\n\nå“åº”è¢«ç»ˆæ­¢ï¼Œå¯èƒ½æ˜¯ä¸Šä¸‹æ–‡è¶…é™æˆ–è€…æ¨¡å‹å†…éƒ¨å®¡æŸ¥ï¼ˆå¤§æ¦‚ç‡ï¼‰çš„åŸå› "
                yield format_openai_chunk(warning_msg, model, response_id)
        elif event_type == 'error':
            logger.error(f"STREAMER [ID: {request_id[:8]}]: æµä¸­å‘ç”Ÿé”™è¯¯: {data}")
            yield format_openai_error_chunk(str(data), model, response_id)
            yield format_openai_finish_chunk(model, response_id, reason='stop')
            return # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œå¯ä»¥ç«‹å³ç»ˆæ­¢

    # åªæœ‰åœ¨ _process_lmarena_stream è‡ªç„¶ç»“æŸå (å³æ”¶åˆ° [DONE]) æ‰æ‰§è¡Œ
    yield format_openai_finish_chunk(model, response_id, reason=finish_reason_to_send)
    logger.info(f"STREAMER [ID: {request_id[:8]}]: æµå¼ç”Ÿæˆå™¨æ­£å¸¸ç»“æŸã€‚")

async def non_stream_response(request_id: str, model: str):
    """èšåˆå†…éƒ¨äº‹ä»¶æµå¹¶è¿”å›å•ä¸ª OpenAI JSON å“åº”ã€‚"""
    response_id = f"chatcmpl-{uuid.uuid4()}"
    logger.info(f"NON-STREAM [ID: {request_id[:8]}]: å¼€å§‹å¤„ç†éæµå¼å“åº”ã€‚")
    
    full_content = []
    finish_reason = "stop"
    
    async for event_type, data in _process_lmarena_stream(request_id):
        if event_type == 'content':
            full_content.append(data)
        elif event_type == 'finish':
            finish_reason = data
            if data == 'content-filter':
                full_content.append("\n\nå“åº”è¢«ç»ˆæ­¢ï¼Œå¯èƒ½æ˜¯ä¸Šä¸‹æ–‡è¶…é™æˆ–è€…æ¨¡å‹å†…éƒ¨å®¡æŸ¥ï¼ˆå¤§æ¦‚ç‡ï¼‰çš„åŸå› ")
            # ä¸è¦åœ¨è¿™é‡Œ breakï¼Œç»§ç»­ç­‰å¾…æ¥è‡ªæµè§ˆå™¨çš„ [DONE] ä¿¡å·ï¼Œä»¥é¿å…ç«æ€æ¡ä»¶
        elif event_type == 'error':
            logger.error(f"NON-STREAM [ID: {request_id[:8]}]: å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {data}")
            
            # ç»Ÿä¸€æµå¼å’Œéæµå¼å“åº”çš„é”™è¯¯çŠ¶æ€ç 
            status_code = 413 if "é™„ä»¶å¤§å°è¶…è¿‡äº†" in str(data) else 500

            error_response = {
                "error": {
                    "message": f"[LMArena Bridge Error]: {data}",
                    "type": "bridge_error",
                    "code": "attachment_too_large" if status_code == 413 else "processing_error"
                }
            }
            return Response(content=json.dumps(error_response, ensure_ascii=False), status_code=status_code, media_type="application/json")

    final_content = "".join(full_content)
    response_data = format_openai_non_stream_response(final_content, model, response_id, reason=finish_reason)
    
    logger.info(f"NON-STREAM [ID: {request_id[:8]}]: å“åº”èšåˆå®Œæˆã€‚")
    return Response(content=json.dumps(response_data, ensure_ascii=False), media_type="application/json")

# --- WebSocket ç«¯ç‚¹ ---
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """å¤„ç†æ¥è‡ªæ²¹çŒ´è„šæœ¬çš„ WebSocket è¿æ¥ã€‚"""
    global browser_ws
    await websocket.accept()
    if browser_ws is not None:
        logger.warning("æ£€æµ‹åˆ°æ–°çš„æ²¹çŒ´è„šæœ¬è¿æ¥ï¼Œæ—§çš„è¿æ¥å°†è¢«æ›¿æ¢ã€‚")
    logger.info("âœ… æ²¹çŒ´è„šæœ¬å·²æˆåŠŸè¿æ¥ WebSocketã€‚")
    browser_ws = websocket
    try:
        while True:
            # ç­‰å¾…å¹¶æ¥æ”¶æ¥è‡ªæ²¹çŒ´è„šæœ¬çš„æ¶ˆæ¯
            message_str = await websocket.receive_text()
            message = json.loads(message_str)
            
            request_id = message.get("request_id")
            data = message.get("data")

            if not request_id or data is None:
                logger.warning(f"æ”¶åˆ°æ¥è‡ªæµè§ˆå™¨çš„æ— æ•ˆæ¶ˆæ¯: {message}")
                continue

            # å°†æ”¶åˆ°çš„æ•°æ®æ”¾å…¥å¯¹åº”çš„å“åº”é€šé“
            if request_id in response_channels:
                await response_channels[request_id].put(data)
            else:
                logger.warning(f"âš ï¸ æ”¶åˆ°æœªçŸ¥æˆ–å·²å…³é—­è¯·æ±‚çš„å“åº”: {request_id}")

    except WebSocketDisconnect:
        logger.warning("âŒ æ²¹çŒ´è„šæœ¬å®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥ã€‚")
    except Exception as e:
        logger.error(f"WebSocket å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
    finally:
        browser_ws = None
        # æ¸…ç†æ‰€æœ‰ç­‰å¾…çš„å“åº”é€šé“ï¼Œä»¥é˜²è¯·æ±‚è¢«æŒ‚èµ·
        for queue in response_channels.values():
            await queue.put({"error": "Browser disconnected during operation"})
        response_channels.clear()
        logger.info("WebSocket è¿æ¥å·²æ¸…ç†ã€‚")

# --- OpenAI å…¼å®¹ API ç«¯ç‚¹ ---
@app.get("/v1/models")
async def get_models():
    """æä¾›å…¼å®¹ OpenAI çš„æ¨¡å‹åˆ—è¡¨ã€‚"""
    if not MODEL_NAME_TO_ID_MAP:
        return JSONResponse(
            status_code=404,
            content={"error": "æ¨¡å‹åˆ—è¡¨ä¸ºç©ºæˆ– 'models.json' æœªæ‰¾åˆ°ã€‚"}
        )
    
    return {
        "object": "list",
        "data": [
            {
                "id": model_name, 
                "object": "model",
                "created": int(time.time()),
                "owned_by": "LMArenaBridge"
            }
            for model_name in MODEL_NAME_TO_ID_MAP.keys()
        ],
    }

@app.post("/internal/request_model_update")
async def request_model_update():
    """
    æ¥æ”¶æ¥è‡ª model_updater.py çš„è¯·æ±‚ï¼Œå¹¶é€šè¿‡ WebSocket æŒ‡ä»¤
    è®©æ²¹çŒ´è„šæœ¬å‘é€é¡µé¢æºç ã€‚
    """
    if not browser_ws:
        logger.warning("MODEL UPDATE: æ”¶åˆ°æ›´æ–°è¯·æ±‚ï¼Œä½†æ²¡æœ‰æµè§ˆå™¨è¿æ¥ã€‚")
        raise HTTPException(status_code=503, detail="Browser client not connected.")
    
    try:
        logger.info("MODEL UPDATE: æ”¶åˆ°æ›´æ–°è¯·æ±‚ï¼Œæ­£åœ¨é€šè¿‡ WebSocket å‘é€æŒ‡ä»¤...")
        await browser_ws.send_text(json.dumps({"command": "send_page_source"}))
        logger.info("MODEL UPDATE: 'send_page_source' æŒ‡ä»¤å·²æˆåŠŸå‘é€ã€‚")
        return JSONResponse({"status": "success", "message": "Request to send page source sent."})
    except Exception as e:
        logger.error(f"MODEL UPDATE: å‘é€æŒ‡ä»¤æ—¶å‡ºé”™: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to send command via WebSocket.")

@app.post("/internal/update_available_models")
async def update_available_models_endpoint(request: Request):
    """
    æ¥æ”¶æ¥è‡ªæ²¹çŒ´è„šæœ¬çš„é¡µé¢ HTMLï¼Œæå–å¹¶æ›´æ–° available_models.jsonã€‚
    """
    html_content = await request.body()
    if not html_content:
        logger.warning("æ¨¡å‹æ›´æ–°è¯·æ±‚æœªæ”¶åˆ°ä»»ä½• HTML å†…å®¹ã€‚")
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "No HTML content received."}
        )
    
    logger.info("æ”¶åˆ°æ¥è‡ªæ²¹çŒ´è„šæœ¬çš„é¡µé¢å†…å®¹ï¼Œå¼€å§‹æå–å¯ç”¨æ¨¡å‹...")
    new_models_list = extract_models_from_html(html_content.decode('utf-8'))
    
    if new_models_list:
        save_available_models(new_models_list)
        return JSONResponse({"status": "success", "message": "Available models file updated."})
    else:
        logger.error("æœªèƒ½ä»æ²¹çŒ´è„šæœ¬æä¾›çš„ HTML ä¸­æå–æ¨¡å‹æ•°æ®ã€‚")
        return JSONResponse(
            status_code=400,
            content={"status": "error", "message": "Could not extract model data from HTML."}
        )


@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """
    å¤„ç†èŠå¤©è¡¥å…¨è¯·æ±‚ã€‚
    æ¥æ”¶ OpenAI æ ¼å¼çš„è¯·æ±‚ï¼Œå°†å…¶è½¬æ¢ä¸º LMArena æ ¼å¼ï¼Œ
    é€šè¿‡ WebSocket å‘é€ç»™æ²¹çŒ´è„šæœ¬ï¼Œç„¶åæµå¼è¿”å›ç»“æœã€‚
    """
    global last_activity_time
    last_activity_time = datetime.now() # æ›´æ–°æ´»åŠ¨æ—¶é—´
    logger.info(f"APIè¯·æ±‚å·²æ”¶åˆ°ï¼Œæ´»åŠ¨æ—¶é—´å·²æ›´æ–°ä¸º: {last_activity_time.strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        openai_req = await request.json()
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ JSON è¯·æ±‚ä½“")

    model_name = openai_req.get("model")
    model_info = MODEL_NAME_TO_ID_MAP.get(model_name, {}) # å…³é”®ä¿®å¤ï¼šå¦‚æœæ¨¡å‹æœªæ‰¾åˆ°ï¼Œè¿”å›ä¸€ä¸ªç©ºå­—å…¸è€Œä¸æ˜¯None
    model_type = model_info.get("type", "text") # é»˜è®¤ä¸º text

    # --- æ–°å¢ï¼šåŸºäºæ¨¡å‹ç±»å‹çš„åˆ¤æ–­é€»è¾‘ ---
    if model_type == 'image':
        logger.info(f"æ£€æµ‹åˆ°æ¨¡å‹ '{model_name}' ç±»å‹ä¸º 'image'ï¼Œå°†é€šè¿‡ä¸»èŠå¤©æ¥å£å¤„ç†ã€‚")
        # å¯¹äºå›¾åƒæ¨¡å‹ï¼Œæˆ‘ä»¬ä¸å†è°ƒç”¨ç‹¬ç«‹çš„å¤„ç†å™¨ï¼Œè€Œæ˜¯å¤ç”¨ä¸»èŠå¤©é€»è¾‘ï¼Œ
        # å› ä¸º _process_lmarena_stream ç°åœ¨å·²ç»èƒ½å¤„ç†å›¾ç‰‡æ•°æ®ã€‚
        # è¿™æ„å‘³ç€å›¾åƒç”Ÿæˆç°åœ¨åŸç”Ÿæ”¯æŒæµå¼å’Œéæµå¼å“åº”ã€‚
        pass # ç»§ç»­æ‰§è¡Œä¸‹é¢çš„é€šç”¨èŠå¤©é€»è¾‘
    # --- æ–‡ç”Ÿå›¾é€»è¾‘ç»“æŸ ---

    # å¦‚æœä¸æ˜¯å›¾åƒæ¨¡å‹ï¼Œåˆ™æ‰§è¡Œæ­£å¸¸çš„æ–‡æœ¬ç”Ÿæˆé€»è¾‘
    load_config()  # å®æ—¶åŠ è½½æœ€æ–°é…ç½®ï¼Œç¡®ä¿ä¼šè¯IDç­‰ä¿¡æ¯æ˜¯æœ€æ–°çš„
    # --- API Key éªŒè¯ ---
    api_key = CONFIG.get("api_key")
    if api_key:
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            raise HTTPException(
                status_code=401,
                detail="æœªæä¾› API Keyã€‚è¯·åœ¨ Authorization å¤´éƒ¨ä¸­ä»¥ 'Bearer YOUR_KEY' æ ¼å¼æä¾›ã€‚"
            )
        
        provided_key = auth_header.split(' ')[1]
        if provided_key != api_key:
            raise HTTPException(
                status_code=401,
                detail="æä¾›çš„ API Key ä¸æ­£ç¡®ã€‚"
            )

    if not browser_ws:
        raise HTTPException(status_code=503, detail="æ²¹çŒ´è„šæœ¬å®¢æˆ·ç«¯æœªè¿æ¥ã€‚è¯·ç¡®ä¿ LMArena é¡µé¢å·²æ‰“å¼€å¹¶æ¿€æ´»è„šæœ¬ã€‚")

    # --- æ¨¡å‹ä¸ä¼šè¯IDæ˜ å°„é€»è¾‘ ---
    session_id, message_id = None, None
    mode_override, battle_target_override = None, None

    if model_name and model_name in MODEL_ENDPOINT_MAP:
        mapping_entry = MODEL_ENDPOINT_MAP[model_name]
        selected_mapping = None

        if isinstance(mapping_entry, list) and mapping_entry:
            selected_mapping = random.choice(mapping_entry)
            logger.info(f"ä¸ºæ¨¡å‹ '{model_name}' ä»IDåˆ—è¡¨ä¸­éšæœºé€‰æ‹©äº†ä¸€ä¸ªæ˜ å°„ã€‚")
        elif isinstance(mapping_entry, dict):
            selected_mapping = mapping_entry
            logger.info(f"ä¸ºæ¨¡å‹ '{model_name}' æ‰¾åˆ°äº†å•ä¸ªç«¯ç‚¹æ˜ å°„ï¼ˆæ—§æ ¼å¼ï¼‰ã€‚")
        
        if selected_mapping:
            session_id = selected_mapping.get("session_id")
            message_id = selected_mapping.get("message_id")
            # å…³é”®ï¼šåŒæ—¶è·å–æ¨¡å¼ä¿¡æ¯
            mode_override = selected_mapping.get("mode") # å¯èƒ½ä¸º None
            battle_target_override = selected_mapping.get("battle_target") # å¯èƒ½ä¸º None
            log_msg = f"å°†ä½¿ç”¨ Session ID: ...{session_id[-6:] if session_id else 'N/A'}"
            if mode_override:
                log_msg += f" (æ¨¡å¼: {mode_override}"
                if mode_override == 'battle':
                    log_msg += f", ç›®æ ‡: {battle_target_override or 'A'}"
                log_msg += ")"
            logger.info(log_msg)

    # å¦‚æœç»è¿‡ä»¥ä¸Šå¤„ç†ï¼Œsession_id ä»ç„¶æ˜¯ Noneï¼Œåˆ™è¿›å…¥å…¨å±€å›é€€é€»è¾‘
    if not session_id:
        if CONFIG.get("use_default_ids_if_mapping_not_found", True):
            session_id = CONFIG.get("session_id")
            message_id = CONFIG.get("message_id")
            # å½“ä½¿ç”¨å…¨å±€IDæ—¶ï¼Œä¸è®¾ç½®æ¨¡å¼è¦†ç›–ï¼Œè®©å…¶ä½¿ç”¨å…¨å±€é…ç½®
            mode_override, battle_target_override = None, None
            logger.info(f"æ¨¡å‹ '{model_name}' æœªæ‰¾åˆ°æœ‰æ•ˆæ˜ å°„ï¼Œæ ¹æ®é…ç½®ä½¿ç”¨å…¨å±€é»˜è®¤ Session ID: ...{session_id[-6:] if session_id else 'N/A'}")
        else:
            logger.error(f"æ¨¡å‹ '{model_name}' æœªåœ¨ 'model_endpoint_map.json' ä¸­æ‰¾åˆ°æœ‰æ•ˆæ˜ å°„ï¼Œä¸”å·²ç¦ç”¨å›é€€åˆ°é»˜è®¤IDã€‚")
            raise HTTPException(
                status_code=400,
                detail=f"æ¨¡å‹ '{model_name}' æ²¡æœ‰é…ç½®ç‹¬ç«‹çš„ä¼šè¯IDã€‚è¯·åœ¨ 'model_endpoint_map.json' ä¸­æ·»åŠ æœ‰æ•ˆæ˜ å°„æˆ–åœ¨ 'config.jsonc' ä¸­å¯ç”¨ 'use_default_ids_if_mapping_not_found'ã€‚"
            )

    # --- éªŒè¯æœ€ç»ˆç¡®å®šçš„ä¼šè¯ä¿¡æ¯ ---
    if not session_id or not message_id or "YOUR_" in session_id or "YOUR_" in message_id:
        raise HTTPException(
            status_code=400,
            detail="æœ€ç»ˆç¡®å®šçš„ä¼šè¯IDæˆ–æ¶ˆæ¯IDæ— æ•ˆã€‚è¯·æ£€æŸ¥ 'model_endpoint_map.json' å’Œ 'config.jsonc' ä¸­çš„é…ç½®ï¼Œæˆ–è¿è¡Œ `id_updater.py` æ¥æ›´æ–°é»˜è®¤å€¼ã€‚"
        )

    if not model_name or model_name not in MODEL_NAME_TO_ID_MAP:
        logger.warning(f"è¯·æ±‚çš„æ¨¡å‹ '{model_name}' ä¸åœ¨ models.json ä¸­ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å‹IDã€‚")

    request_id = str(uuid.uuid4())
    response_channels[request_id] = asyncio.Queue()
    logger.info(f"API CALL [ID: {request_id[:8]}]: å·²åˆ›å»ºå“åº”é€šé“ã€‚")

    try:
        # 1. è½¬æ¢è¯·æ±‚ï¼Œä¼ å…¥å¯èƒ½å­˜åœ¨çš„æ¨¡å¼è¦†ç›–ä¿¡æ¯
        lmarena_payload = convert_openai_to_lmarena_payload(
            openai_req,
            session_id,
            message_id,
            mode_override=mode_override,
            battle_target_override=battle_target_override
        )
        
        # 2. åŒ…è£…æˆå‘é€ç»™æµè§ˆå™¨çš„æ¶ˆæ¯
        message_to_browser = {
            "request_id": request_id,
            "payload": lmarena_payload
        }
        
        # 3. é€šè¿‡ WebSocket å‘é€
        logger.info(f"API CALL [ID: {request_id[:8]}]: æ­£åœ¨é€šè¿‡ WebSocket å‘é€è½½è·åˆ°æ²¹çŒ´è„šæœ¬ã€‚")
        await browser_ws.send_text(json.dumps(message_to_browser))

        # 4. æ ¹æ® stream å‚æ•°å†³å®šè¿”å›ç±»å‹
        is_stream = openai_req.get("stream", True)

        if is_stream:
            # è¿”å›æµå¼å“åº”
            return StreamingResponse(
                stream_generator(request_id, model_name or "default_model"),
                media_type="text/event-stream"
            )
        else:
            # è¿”å›éæµå¼å“åº”
            return await non_stream_response(request_id, model_name or "default_model")
    except Exception as e:
        # å¦‚æœåœ¨è®¾ç½®è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œæ¸…ç†é€šé“
        if request_id in response_channels:
            del response_channels[request_id]
        logger.error(f"API CALL [ID: {request_id[:8]}]: å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# --- å†…éƒ¨é€šä¿¡ç«¯ç‚¹ ---
@app.post("/internal/start_id_capture")
async def start_id_capture():
    """
    æ¥æ”¶æ¥è‡ª id_updater.py çš„é€šçŸ¥ï¼Œå¹¶é€šè¿‡ WebSocket æŒ‡ä»¤
    æ¿€æ´»æ²¹çŒ´è„šæœ¬çš„ ID æ•è·æ¨¡å¼ã€‚
    """
    if not browser_ws:
        logger.warning("ID CAPTURE: æ”¶åˆ°æ¿€æ´»è¯·æ±‚ï¼Œä½†æ²¡æœ‰æµè§ˆå™¨è¿æ¥ã€‚")
        raise HTTPException(status_code=503, detail="Browser client not connected.")
    
    try:
        logger.info("ID CAPTURE: æ”¶åˆ°æ¿€æ´»è¯·æ±‚ï¼Œæ­£åœ¨é€šè¿‡ WebSocket å‘é€æŒ‡ä»¤...")
        await browser_ws.send_text(json.dumps({"command": "activate_id_capture"}))
        logger.info("ID CAPTURE: æ¿€æ´»æŒ‡ä»¤å·²æˆåŠŸå‘é€ã€‚")
        return JSONResponse({"status": "success", "message": "Activation command sent."})
    except Exception as e:
        logger.error(f"ID CAPTURE: å‘é€æ¿€æ´»æŒ‡ä»¤æ—¶å‡ºé”™: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to send command via WebSocket.")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # å»ºè®®ä» config.jsonc ä¸­è¯»å–ç«¯å£ï¼Œæ­¤å¤„ä¸ºä¸´æ—¶ç¡¬ç¼–ç 
    api_port = 5102
    logger.info(f"ğŸš€ LMArena Bridge v2.0 API æœåŠ¡å™¨æ­£åœ¨å¯åŠ¨...")
    logger.info(f"   - ç›‘å¬åœ°å€: http://127.0.0.1:{api_port}")
    logger.info(f"   - WebSocket ç«¯ç‚¹: ws://127.0.0.1:{api_port}/ws")
    
    uvicorn.run(app, host="0.0.0.0", port=api_port)
